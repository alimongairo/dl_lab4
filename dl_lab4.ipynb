{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fbJPvWhAgYRE"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers\n",
        "!pip install -q torchdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "myz4Wu9dhBYq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchtext\n",
        "import torchdata\n",
        "from transformers import BertModel, BertConfig\n",
        "from torchtext.transforms import BERTTokenizer\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "dWilwPs0mFAj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, test_ds = torchtext.datasets.IMDB(split=('train', 'test'))\n",
        "train_data = DataLoader(train_ds, batch_size=1, shuffle=True)\n",
        "test_data = DataLoader(test_ds, batch_size=1, shuffle=True)"
      ],
      "metadata": {
        "id": "wG1JJBaClssf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchtext\n",
        "from torchtext.models import RobertaClassificationHead\n",
        "from torchtext.functional import to_tensor\n",
        "xlmr_large = torchtext.models.XLMR_LARGE_ENCODER\n",
        "classifier_head = torchtext.models.RobertaClassificationHead(num_classes=2, input_dim = 1024)\n",
        "model = xlmr_large.get_model(head=classifier_head).to(device)\n",
        "transform = xlmr_large.transform()\n",
        "# input_batch = list(b1)\n",
        "# model_input = to_tensor(transform(input_batch), padding_value=1).to(device)\n",
        "# output = model(model_input)\n",
        "# output.shape"
      ],
      "metadata": {
        "id": "QX4KBerA3Wpk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 1\n",
        "n_classes = 2"
      ],
      "metadata": {
        "id": "1FxbhkMmz2_3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "for epoch in range(n_epochs):\n",
        "    for i, batch in enumerate(train_data):\n",
        "        # if i == 500:\n",
        "        #     break\n",
        "        optim.zero_grad()\n",
        "        # print(list(batch[1]))\n",
        "        model_input = to_tensor(transform(list(batch[1])), padding_value=1).to(device)\n",
        "        predict = model(model_input)\n",
        "        loss = loss_func(predict.view(-1, n_classes),\n",
        "                         batch[0].to(device).view(-1),)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        torch.cuda.empty_cache()\n",
        "        if i % 100 == 0:\n",
        "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')"
      ],
      "metadata": {
        "id": "gelKyYyOvNRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "502ca16d-90c1-4c05-c9bc-d68117c9a6ec"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 0.0\n",
            "epoch: 0, step: 100, loss: 0.0\n",
            "epoch: 0, step: 200, loss: 0.0\n",
            "epoch: 0, step: 300, loss: 0.0\n",
            "epoch: 0, step: 400, loss: 0.0\n",
            "epoch: 0, step: 500, loss: 0.0\n",
            "epoch: 0, step: 600, loss: 0.0\n",
            "epoch: 0, step: 700, loss: 0.0\n",
            "epoch: 0, step: 800, loss: 0.0\n",
            "epoch: 0, step: 900, loss: 0.0\n",
            "epoch: 0, step: 1000, loss: 0.0\n",
            "epoch: 0, step: 1100, loss: 0.0\n",
            "epoch: 0, step: 1200, loss: 0.0\n",
            "epoch: 0, step: 1300, loss: 0.0\n",
            "epoch: 0, step: 1400, loss: 0.0\n",
            "epoch: 0, step: 1500, loss: 0.0\n",
            "epoch: 0, step: 1600, loss: 0.0\n",
            "epoch: 0, step: 1700, loss: 0.0\n",
            "epoch: 0, step: 1800, loss: 0.0\n",
            "epoch: 0, step: 1900, loss: 0.0\n",
            "epoch: 0, step: 2000, loss: 0.0\n",
            "epoch: 0, step: 2100, loss: 0.0\n",
            "epoch: 0, step: 2200, loss: 0.0\n",
            "epoch: 0, step: 2300, loss: 0.0\n",
            "epoch: 0, step: 2400, loss: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), f'./model_text_{epoch}.pth')"
      ],
      "metadata": {
        "id": "oEtizT6TU12b"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "0D5zJuy70BWS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "pred = []\n",
        "tar = []\n",
        "for i, batch in enumerate(test_data):\n",
        "  # print(batch[0])\n",
        "  if i == 500:\n",
        "    break\n",
        "  res = model(to_tensor(transform(list(batch[1])), padding_value=1).to(device))\n",
        "  if res[0][0] > res[0][1]:\n",
        "    res_class = 0\n",
        "  else: res_class = 1\n",
        "  pred.append(res_class)\n",
        "  tar.append(int(batch[0][0]))\n",
        "  # res_class = torch.tensor(res_class).unsqueeze(0)\n",
        "  torch.cuda.empty_cache()\n",
        "  # print(batch[0], res_class) \n",
        "# print(tar)\n",
        "# print(pred)"
      ],
      "metadata": {
        "id": "FnpBsubALyuK"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_score(tar, pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVCXtQ5M2gH7",
        "outputId": "10d49ba0-a5b9-49c5-921e-7d86d7932514"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ]
}